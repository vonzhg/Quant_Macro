{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 8: Advanced Numerical Methods and Accuracy Assessment\n",
    "## Howard's Policy Improvement, EGM, and Euler Equation Errors\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ Lab Philosophy\n",
    "\n",
    "In Lab 7, we implemented the fundamental algorithms (VFI, Time Iteration). Now we focus on **computational efficiency** and **accuracy assessment** ‚Äî essential skills for solving larger, more complex models.\n",
    "\n",
    "A key principle: **Speed and accuracy are not competing goals**. Better algorithms often achieve both simultaneously.\n",
    "\n",
    "### üìö Coverage\n",
    "\n",
    "**Part 1: Accelerating VFI**\n",
    "-   Howard's Policy Improvement (Policy Iteration within VFI)\n",
    "-   Exploiting monotonicity with binary search\n",
    "-   Measuring speedups systematically\n",
    "\n",
    "**Part 2: Endogenous Grid Method (EGM)**\n",
    "-   The key insight: inverting the problem\n",
    "-   Eliminating the inner optimization loop\n",
    "-   Implementation for the RBC model\n",
    "\n",
    "**Part 3: Accuracy Assessment**\n",
    "-   Computing Euler equation errors\n",
    "-   Visualizing error distributions\n",
    "-   The $\\log_{10}$ error interpretation\n",
    "\n",
    "**Part 4: Sensitivity Analysis**\n",
    "-   Grid density effects\n",
    "-   Tolerance choice\n",
    "-   Interpolation method comparison\n",
    "\n",
    "**Part 5: Impulse Response Analysis**\n",
    "-   Generating IRFs to productivity shocks\n",
    "-   Verifying economic plausibility\n",
    "\n",
    "---\n",
    "\n",
    "### üîß The Research Architect Workflow\n",
    "\n",
    "Today's emphasis: **Validation through multiple lenses**\n",
    "1. Does the algorithm converge faster? (Speedup measurement)\n",
    "2. Is the solution accurate? (Euler equation errors)\n",
    "3. Is it economically sensible? (Impulse responses)\n",
    "4. Is it robust? (Sensitivity analysis)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T01:27:53.700837Z",
     "start_time": "2025-12-02T01:27:52.714632Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interpolate\n",
    "from scipy.optimize import brentq, minimize_scalar\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = [10, 6]\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "print(\"Libraries loaded successfully!\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zfeng/Library/CloudStorage/OneDrive-UniversityofNebraska/GitHub/AI_ML_Macro/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T01:27:53.718082Z",
     "start_time": "2025-12-02T01:27:53.709619Z"
    }
   },
   "source": [
    "# =============================================================================\n",
    "# RBC Model Class (from Lab 7, with minor enhancements)\n",
    "# =============================================================================\n",
    "\n",
    "class RBCModel:\n",
    "    \"\"\"\n",
    "    Real Business Cycle Model - enhanced version with utility derivatives.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 alpha=0.33,\n",
    "                 beta=0.99,\n",
    "                 delta=0.025,\n",
    "                 sigma_crra=1.0,\n",
    "                 rho=0.95,\n",
    "                 sigma_eps=0.007,\n",
    "                 n_z=7,\n",
    "                 n_k=100):\n",
    "        \n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.delta = delta\n",
    "        self.sigma_crra = sigma_crra\n",
    "        self.rho = rho\n",
    "        self.sigma_eps = sigma_eps\n",
    "        self.n_z = n_z\n",
    "        self.n_k = n_k\n",
    "        \n",
    "        self._compute_steady_state()\n",
    "        self._discretize_productivity()\n",
    "        self._construct_capital_grid()\n",
    "        \n",
    "    def _compute_steady_state(self):\n",
    "        r_ss = 1/self.beta - (1 - self.delta)\n",
    "        self.k_ss = (self.alpha / r_ss) ** (1 / (1 - self.alpha))\n",
    "        self.y_ss = self.k_ss ** self.alpha\n",
    "        self.c_ss = self.y_ss - self.delta * self.k_ss\n",
    "        self.i_ss = self.delta * self.k_ss\n",
    "        \n",
    "    def _discretize_productivity(self):\n",
    "        from scipy.special import erfc\n",
    "        \n",
    "        sigma_z = self.sigma_eps / np.sqrt(1 - self.rho**2)\n",
    "        z_max = 3 * sigma_z\n",
    "        z_min = -z_max\n",
    "        \n",
    "        log_z_grid = np.linspace(z_min, z_max, self.n_z)\n",
    "        step = log_z_grid[1] - log_z_grid[0]\n",
    "        \n",
    "        self.z_grid = np.exp(log_z_grid)\n",
    "        self.log_z_grid = log_z_grid\n",
    "        \n",
    "        self.Pi = np.zeros((self.n_z, self.n_z))\n",
    "        \n",
    "        def std_normal_cdf(x):\n",
    "            return 0.5 * erfc(-x / np.sqrt(2))\n",
    "        \n",
    "        for i in range(self.n_z):\n",
    "            for j in range(self.n_z):\n",
    "                if j == 0:\n",
    "                    self.Pi[i, j] = std_normal_cdf(\n",
    "                        (log_z_grid[0] + step/2 - self.rho * log_z_grid[i]) / self.sigma_eps\n",
    "                    )\n",
    "                elif j == self.n_z - 1:\n",
    "                    self.Pi[i, j] = 1 - std_normal_cdf(\n",
    "                        (log_z_grid[-1] - step/2 - self.rho * log_z_grid[i]) / self.sigma_eps\n",
    "                    )\n",
    "                else:\n",
    "                    self.Pi[i, j] = std_normal_cdf(\n",
    "                        (log_z_grid[j] + step/2 - self.rho * log_z_grid[i]) / self.sigma_eps\n",
    "                    ) - std_normal_cdf(\n",
    "                        (log_z_grid[j] - step/2 - self.rho * log_z_grid[i]) / self.sigma_eps\n",
    "                    )\n",
    "        \n",
    "    def _construct_capital_grid(self, grid_type='clustered'):\n",
    "        k_min = 0.5 * self.k_ss\n",
    "        k_max = 1.5 * self.k_ss\n",
    "        \n",
    "        if grid_type == 'uniform':\n",
    "            self.k_grid = np.linspace(k_min, k_max, self.n_k)\n",
    "        elif grid_type == 'clustered':\n",
    "            x = np.linspace(0, 1, self.n_k)\n",
    "            stretch = 2.0\n",
    "            x_transformed = np.sinh(stretch * (x - 0.5)) / np.sinh(stretch * 0.5)\n",
    "            x_transformed = (x_transformed + 1) / 2\n",
    "            self.k_grid = k_min + (k_max - k_min) * x_transformed\n",
    "    \n",
    "    def utility(self, c):\n",
    "        c = np.maximum(c, 1e-10)\n",
    "        if self.sigma_crra == 1.0:\n",
    "            return np.log(c)\n",
    "        else:\n",
    "            return (c ** (1 - self.sigma_crra) - 1) / (1 - self.sigma_crra)\n",
    "    \n",
    "    def marginal_utility(self, c):\n",
    "        return np.maximum(c, 1e-10) ** (-self.sigma_crra)\n",
    "    \n",
    "    def inv_marginal_utility(self, mu):\n",
    "        return np.maximum(mu, 1e-10) ** (-1 / self.sigma_crra)\n",
    "    \n",
    "    def production(self, k, z):\n",
    "        return z * k ** self.alpha\n",
    "    \n",
    "    def marginal_product_k(self, k, z):\n",
    "        return self.alpha * z * np.maximum(k, 1e-10) ** (self.alpha - 1)\n",
    "    \n",
    "    def gross_return(self, k, z):\n",
    "        \"\"\"Gross return on capital: R = MPK + 1 - delta\"\"\"\n",
    "        return self.marginal_product_k(k, z) + 1 - self.delta\n",
    "\n",
    "# Initialize the model\n",
    "model = RBCModel(n_k=100, n_z=7)\n",
    "print(f\"Model initialized: k_ss = {model.k_ss:.4f}, c_ss = {model.c_ss:.4f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized: k_ss = 28.3484, c_ss = 2.3066\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Accelerating VFI\n",
    "\n",
    "## 1.1 Howard's Policy Improvement\n",
    "\n",
    "**The Key Insight**: After finding the optimal policy at each iteration, we can \"exploit\" this policy for multiple periods before re-optimizing. This converts the expensive Bellman maximization into cheaper policy evaluations.\n",
    "\n",
    "**Algorithm:**\n",
    "```\n",
    "1. Start with V_0, find optimal policy g_0\n",
    "2. For each VFI iteration:\n",
    "   a. Compute optimal policy g from current V\n",
    "   b. For m = 1 to M (Howard steps):\n",
    "      - Update V by evaluating (not optimizing!) under policy g:\n",
    "        V(k,z) = u(c(k,z)) + Œ≤ E[V(k',z') | z]\n",
    "        where k' = g(k,z)\n",
    "   c. Check convergence\n",
    "```\n",
    "\n",
    "**Why It Works**: The policy converges faster than the value function. Howard steps \"catch up\" the value function to the nearly-converged policy at low cost.\n",
    "\n",
    "**Typical Speedup**: 10-100x depending on the model and number of Howard steps."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T01:27:53.732421Z",
     "start_time": "2025-12-02T01:27:53.724832Z"
    }
   },
   "source": [
    "# =============================================================================\n",
    "# 1.2 VFI with Howard's Policy Improvement\n",
    "# =============================================================================\n",
    "\n",
    "class VFIHoward:\n",
    "    \"\"\"\n",
    "    Value Function Iteration with Howard's Policy Improvement.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, howard_steps=20):\n",
    "        self.model = model\n",
    "        self.howard_steps = howard_steps\n",
    "        \n",
    "        # Initialize\n",
    "        self.V = np.zeros((model.n_k, model.n_z))\n",
    "        self.policy_k_idx = np.zeros((model.n_k, model.n_z), dtype=int)\n",
    "        self.policy_c = np.zeros((model.n_k, model.n_z))\n",
    "        \n",
    "        # Precompute feasible consumption for all (k, z, k') combinations\n",
    "        self._precompute_consumption()\n",
    "        \n",
    "        self.convergence_history = []\n",
    "        self.timing_info = {}\n",
    "        \n",
    "    def _precompute_consumption(self):\n",
    "        \"\"\"Precompute consumption matrix for efficiency.\"\"\"\n",
    "        self.consumption_matrix = np.zeros((self.model.n_k, self.model.n_z, self.model.n_k))\n",
    "        self.feasible = np.zeros((self.model.n_k, self.model.n_z, self.model.n_k), dtype=bool)\n",
    "        \n",
    "        for i_k, k in enumerate(self.model.k_grid):\n",
    "            for i_z, z in enumerate(self.model.z_grid):\n",
    "                resources = z * k**self.model.alpha + (1 - self.model.delta) * k\n",
    "                for i_kp, k_prime in enumerate(self.model.k_grid):\n",
    "                    c = resources - k_prime\n",
    "                    self.consumption_matrix[i_k, i_z, i_kp] = c\n",
    "                    self.feasible[i_k, i_z, i_kp] = c > 0\n",
    "    \n",
    "    def _howard_step(self):\n",
    "        \"\"\"\n",
    "        Policy evaluation step: update V given fixed policy.\n",
    "        \"\"\"\n",
    "        V_new = np.zeros_like(self.V)\n",
    "        \n",
    "        for i_k in range(self.model.n_k):\n",
    "            for i_z in range(self.model.n_z):\n",
    "                i_kp = self.policy_k_idx[i_k, i_z]\n",
    "                c = self.consumption_matrix[i_k, i_z, i_kp]\n",
    "                \n",
    "                # Compute expected continuation value\n",
    "                EV = np.dot(self.model.Pi[i_z, :], self.V[i_kp, :])\n",
    "                \n",
    "                V_new[i_k, i_z] = self.model.utility(c) + self.model.beta * EV\n",
    "        \n",
    "        self.V = V_new\n",
    "    \n",
    "    def _bellman_step(self):\n",
    "        \"\"\"\n",
    "        Full Bellman optimization step.\n",
    "        \"\"\"\n",
    "        V_new = np.zeros_like(self.V)\n",
    "        \n",
    "        for i_k in range(self.model.n_k):\n",
    "            for i_z in range(self.model.n_z):\n",
    "                best_val = -np.inf\n",
    "                best_i_kp = 0\n",
    "                \n",
    "                for i_kp in range(self.model.n_k):\n",
    "                    if not self.feasible[i_k, i_z, i_kp]:\n",
    "                        continue\n",
    "                    \n",
    "                    c = self.consumption_matrix[i_k, i_z, i_kp]\n",
    "                    EV = np.dot(self.model.Pi[i_z, :], self.V[i_kp, :])\n",
    "                    val = self.model.utility(c) + self.model.beta * EV\n",
    "                    \n",
    "                    if val > best_val:\n",
    "                        best_val = val\n",
    "                        best_i_kp = i_kp\n",
    "                \n",
    "                V_new[i_k, i_z] = best_val\n",
    "                self.policy_k_idx[i_k, i_z] = best_i_kp\n",
    "                self.policy_c[i_k, i_z] = self.consumption_matrix[i_k, i_z, best_i_kp]\n",
    "        \n",
    "        self.V = V_new\n",
    "    \n",
    "    def solve(self, tol=1e-6, max_iter=500, verbose=True):\n",
    "        \"\"\"\n",
    "        Solve using VFI with Howard's policy improvement.\n",
    "        \"\"\"\n",
    "        print(f\"\\n=== VFI with Howard's Policy Improvement (M={self.howard_steps}) ===\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        n_bellman = 0\n",
    "        n_howard = 0\n",
    "        \n",
    "        for iteration in range(max_iter):\n",
    "            V_old = self.V.copy()\n",
    "            \n",
    "            # Full Bellman step (optimization)\n",
    "            self._bellman_step()\n",
    "            n_bellman += 1\n",
    "            \n",
    "            # Howard steps (policy evaluation only)\n",
    "            for _ in range(self.howard_steps):\n",
    "                self._howard_step()\n",
    "                n_howard += 1\n",
    "            \n",
    "            # Check convergence\n",
    "            diff = np.max(np.abs(self.V - V_old))\n",
    "            self.convergence_history.append(diff)\n",
    "            \n",
    "            if verbose and iteration % 10 == 0:\n",
    "                print(f\"Iteration {iteration:4d}: ||V - V_old|| = {diff:.2e}\")\n",
    "            \n",
    "            if diff < tol:\n",
    "                elapsed = time.time() - start_time\n",
    "                self.timing_info = {\n",
    "                    'elapsed': elapsed,\n",
    "                    'n_bellman': n_bellman,\n",
    "                    'n_howard': n_howard,\n",
    "                    'iterations': iteration + 1\n",
    "                }\n",
    "                print(f\"\\nConverged in {iteration+1} iterations ({elapsed:.2f} seconds)\")\n",
    "                print(f\"Bellman steps: {n_bellman}, Howard steps: {n_howard}\")\n",
    "                return True\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    def get_policy_k(self):\n",
    "        \"\"\"Return capital policy on the grid.\"\"\"\n",
    "        policy_k = np.zeros((self.model.n_k, self.model.n_z))\n",
    "        for i_k in range(self.model.n_k):\n",
    "            for i_z in range(self.model.n_z):\n",
    "                policy_k[i_k, i_z] = self.model.k_grid[self.policy_k_idx[i_k, i_z]]\n",
    "        return policy_k"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T01:29:08.441749Z",
     "start_time": "2025-12-02T01:27:53.736332Z"
    }
   },
   "source": [
    "# Compare VFI with and without Howard's improvement\n",
    "print(\"=\"*60)\n",
    "print(\"COMPARISON: Standard VFI vs Howard's Policy Improvement\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Standard VFI (Howard steps = 0)\n",
    "vfi_standard = VFIHoward(model, howard_steps=0)\n",
    "vfi_standard.solve(tol=1e-6, max_iter=1000, verbose=False)\n",
    "time_standard = vfi_standard.timing_info['elapsed']\n",
    "\n",
    "# VFI with Howard (M=20)\n",
    "vfi_howard = VFIHoward(model, howard_steps=20)\n",
    "vfi_howard.solve(tol=1e-6, max_iter=1000, verbose=False)\n",
    "time_howard = vfi_howard.timing_info['elapsed']\n",
    "\n",
    "print(f\"\\n{'Method':<30} {'Time (s)':>12} {'Speedup':>12}\")\n",
    "print(\"-\"*60)\n",
    "print(f\"{'Standard VFI':<30} {time_standard:>12.2f} {'1.0x':>12}\")\n",
    "print(f\"{'VFI + Howard (M=20)':<30} {time_howard:>12.2f} {time_standard/time_howard:>11.1f}x\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "COMPARISON: Standard VFI vs Howard's Policy Improvement\n",
      "============================================================\n",
      "\n",
      "=== VFI with Howard's Policy Improvement (M=0) ===\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[4]\u001B[39m\u001B[32m, line 8\u001B[39m\n\u001B[32m      6\u001B[39m \u001B[38;5;66;03m# Standard VFI (Howard steps = 0)\u001B[39;00m\n\u001B[32m      7\u001B[39m vfi_standard = VFIHoward(model, howard_steps=\u001B[32m0\u001B[39m)\n\u001B[32m----> \u001B[39m\u001B[32m8\u001B[39m \u001B[43mvfi_standard\u001B[49m\u001B[43m.\u001B[49m\u001B[43msolve\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtol\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m1e-6\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_iter\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m1000\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[32m      9\u001B[39m time_standard = vfi_standard.timing_info[\u001B[33m'\u001B[39m\u001B[33melapsed\u001B[39m\u001B[33m'\u001B[39m]\n\u001B[32m     11\u001B[39m \u001B[38;5;66;03m# VFI with Howard (M=20)\u001B[39;00m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[3]\u001B[39m\u001B[32m, line 99\u001B[39m, in \u001B[36mVFIHoward.solve\u001B[39m\u001B[34m(self, tol, max_iter, verbose)\u001B[39m\n\u001B[32m     96\u001B[39m V_old = \u001B[38;5;28mself\u001B[39m.V.copy()\n\u001B[32m     98\u001B[39m \u001B[38;5;66;03m# Full Bellman step (optimization)\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m99\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_bellman_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    100\u001B[39m n_bellman += \u001B[32m1\u001B[39m\n\u001B[32m    102\u001B[39m \u001B[38;5;66;03m# Howard steps (policy evaluation only)\u001B[39;00m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[3]\u001B[39m\u001B[32m, line 73\u001B[39m, in \u001B[36mVFIHoward._bellman_step\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m     71\u001B[39m c = \u001B[38;5;28mself\u001B[39m.consumption_matrix[i_k, i_z, i_kp]\n\u001B[32m     72\u001B[39m EV = np.dot(\u001B[38;5;28mself\u001B[39m.model.Pi[i_z, :], \u001B[38;5;28mself\u001B[39m.V[i_kp, :])\n\u001B[32m---> \u001B[39m\u001B[32m73\u001B[39m val = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mutility\u001B[49m\u001B[43m(\u001B[49m\u001B[43mc\u001B[49m\u001B[43m)\u001B[49m + \u001B[38;5;28mself\u001B[39m.model.beta * EV\n\u001B[32m     75\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m val > best_val:\n\u001B[32m     76\u001B[39m     best_val = val\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[2]\u001B[39m\u001B[32m, line 91\u001B[39m, in \u001B[36mRBCModel.utility\u001B[39m\u001B[34m(self, c)\u001B[39m\n\u001B[32m     89\u001B[39m c = np.maximum(c, \u001B[32m1e-10\u001B[39m)\n\u001B[32m     90\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.sigma_crra == \u001B[32m1.0\u001B[39m:\n\u001B[32m---> \u001B[39m\u001B[32m91\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mnp\u001B[49m\u001B[43m.\u001B[49m\u001B[43mlog\u001B[49m\u001B[43m(\u001B[49m\u001B[43mc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     92\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m     93\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m (c ** (\u001B[32m1\u001B[39m - \u001B[38;5;28mself\u001B[39m.sigma_crra) - \u001B[32m1\u001B[39m) / (\u001B[32m1\u001B[39m - \u001B[38;5;28mself\u001B[39m.sigma_crra)\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Visualize convergence comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Convergence by iteration\n",
    "axes[0].semilogy(vfi_standard.convergence_history, 'b-', label='Standard VFI', alpha=0.7)\n",
    "axes[0].semilogy(vfi_howard.convergence_history, 'r-', label='VFI + Howard', alpha=0.7)\n",
    "axes[0].set_xlabel('Iteration')\n",
    "axes[0].set_ylabel('||V - V_old||')\n",
    "axes[0].set_title('Convergence by Iteration')\n",
    "axes[0].legend()\n",
    "\n",
    "# Policy comparison\n",
    "i_z_mid = model.n_z // 2\n",
    "policy_standard = vfi_standard.get_policy_k()\n",
    "policy_howard = vfi_howard.get_policy_k()\n",
    "\n",
    "axes[1].plot(model.k_grid, policy_standard[:, i_z_mid], 'b-', \n",
    "             label='Standard VFI', linewidth=2)\n",
    "axes[1].plot(model.k_grid, policy_howard[:, i_z_mid], 'r--', \n",
    "             label='VFI + Howard', linewidth=2)\n",
    "axes[1].plot(model.k_grid, model.k_grid, 'k:', alpha=0.3, label='45¬∞ line')\n",
    "axes[1].set_xlabel('Capital (k)')\n",
    "axes[1].set_ylabel(\"k'\")\n",
    "axes[1].set_title('Capital Policy Comparison')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Check that policies are nearly identical\n",
    "max_diff = np.max(np.abs(policy_standard - policy_howard))\n",
    "print(f\"\\nMax policy difference: {max_diff:.2e}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Exploiting Monotonicity with Binary Search\n",
    "\n",
    "**Economic Insight**: The optimal capital policy $k'(k, z)$ is monotonically increasing in $k$. Once we find the optimal $k'$ for capital level $k_i$, we know the optimal $k'$ for $k_{i+1}$ must be at least as large.\n",
    "\n",
    "**Algorithm Enhancement:**\n",
    "```\n",
    "For each z:\n",
    "  lower_bound = 0\n",
    "  For k = k_1 to k_N (ascending):\n",
    "    Search for optimal k' only in [lower_bound, n_k]\n",
    "    lower_bound = index of optimal k'\n",
    "```\n",
    "\n",
    "This reduces the inner loop from $O(n_k)$ to $O(1)$ on average (or $O(\\log n_k)$ with binary search)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# 1.4 VFI with Monotonicity Exploitation\n",
    "# =============================================================================\n",
    "\n",
    "class VFIMonotone:\n",
    "    \"\"\"\n",
    "    VFI exploiting monotonicity of the policy function.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, howard_steps=20):\n",
    "        self.model = model\n",
    "        self.howard_steps = howard_steps\n",
    "        \n",
    "        self.V = np.zeros((model.n_k, model.n_z))\n",
    "        self.policy_k_idx = np.zeros((model.n_k, model.n_z), dtype=int)\n",
    "        self.policy_c = np.zeros((model.n_k, model.n_z))\n",
    "        \n",
    "        self._precompute_consumption()\n",
    "        self.convergence_history = []\n",
    "        self.timing_info = {}\n",
    "        \n",
    "    def _precompute_consumption(self):\n",
    "        self.consumption_matrix = np.zeros((self.model.n_k, self.model.n_z, self.model.n_k))\n",
    "        self.feasible = np.zeros((self.model.n_k, self.model.n_z, self.model.n_k), dtype=bool)\n",
    "        \n",
    "        for i_k, k in enumerate(self.model.k_grid):\n",
    "            for i_z, z in enumerate(self.model.z_grid):\n",
    "                resources = z * k**self.model.alpha + (1 - self.model.delta) * k\n",
    "                for i_kp, k_prime in enumerate(self.model.k_grid):\n",
    "                    c = resources - k_prime\n",
    "                    self.consumption_matrix[i_k, i_z, i_kp] = c\n",
    "                    self.feasible[i_k, i_z, i_kp] = c > 0\n",
    "    \n",
    "    def _howard_step(self):\n",
    "        V_new = np.zeros_like(self.V)\n",
    "        for i_k in range(self.model.n_k):\n",
    "            for i_z in range(self.model.n_z):\n",
    "                i_kp = self.policy_k_idx[i_k, i_z]\n",
    "                c = self.consumption_matrix[i_k, i_z, i_kp]\n",
    "                EV = np.dot(self.model.Pi[i_z, :], self.V[i_kp, :])\n",
    "                V_new[i_k, i_z] = self.model.utility(c) + self.model.beta * EV\n",
    "        self.V = V_new\n",
    "    \n",
    "    def _bellman_step_monotone(self):\n",
    "        \"\"\"\n",
    "        Bellman step exploiting monotonicity.\n",
    "        \"\"\"\n",
    "        V_new = np.zeros_like(self.V)\n",
    "        \n",
    "        for i_z in range(self.model.n_z):\n",
    "            lower_bound = 0  # Start search from beginning\n",
    "            \n",
    "            for i_k in range(self.model.n_k):\n",
    "                best_val = -np.inf\n",
    "                best_i_kp = lower_bound\n",
    "                \n",
    "                # Search only from lower_bound (monotonicity)\n",
    "                for i_kp in range(lower_bound, self.model.n_k):\n",
    "                    if not self.feasible[i_k, i_z, i_kp]:\n",
    "                        continue\n",
    "                    \n",
    "                    c = self.consumption_matrix[i_k, i_z, i_kp]\n",
    "                    EV = np.dot(self.model.Pi[i_z, :], self.V[i_kp, :])\n",
    "                    val = self.model.utility(c) + self.model.beta * EV\n",
    "                    \n",
    "                    if val > best_val:\n",
    "                        best_val = val\n",
    "                        best_i_kp = i_kp\n",
    "                    elif val < best_val - 1e-10:\n",
    "                        # Objective is concave, so we can stop\n",
    "                        break\n",
    "                \n",
    "                V_new[i_k, i_z] = best_val\n",
    "                self.policy_k_idx[i_k, i_z] = best_i_kp\n",
    "                self.policy_c[i_k, i_z] = self.consumption_matrix[i_k, i_z, best_i_kp]\n",
    "                \n",
    "                # Update lower bound for next k (monotonicity)\n",
    "                lower_bound = best_i_kp\n",
    "        \n",
    "        self.V = V_new\n",
    "    \n",
    "    def solve(self, tol=1e-6, max_iter=500, verbose=True):\n",
    "        print(f\"\\n=== VFI with Monotonicity + Howard (M={self.howard_steps}) ===\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for iteration in range(max_iter):\n",
    "            V_old = self.V.copy()\n",
    "            \n",
    "            self._bellman_step_monotone()\n",
    "            \n",
    "            for _ in range(self.howard_steps):\n",
    "                self._howard_step()\n",
    "            \n",
    "            diff = np.max(np.abs(self.V - V_old))\n",
    "            self.convergence_history.append(diff)\n",
    "            \n",
    "            if verbose and iteration % 10 == 0:\n",
    "                print(f\"Iteration {iteration:4d}: ||V - V_old|| = {diff:.2e}\")\n",
    "            \n",
    "            if diff < tol:\n",
    "                elapsed = time.time() - start_time\n",
    "                self.timing_info['elapsed'] = elapsed\n",
    "                self.timing_info['iterations'] = iteration + 1\n",
    "                print(f\"\\nConverged in {iteration+1} iterations ({elapsed:.2f} seconds)\")\n",
    "                return True\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    def get_policy_k(self):\n",
    "        policy_k = np.zeros((self.model.n_k, self.model.n_z))\n",
    "        for i_k in range(self.model.n_k):\n",
    "            for i_z in range(self.model.n_z):\n",
    "                policy_k[i_k, i_z] = self.model.k_grid[self.policy_k_idx[i_k, i_z]]\n",
    "        return policy_k"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Compare all three methods\n",
    "vfi_monotone = VFIMonotone(model, howard_steps=20)\n",
    "vfi_monotone.solve(tol=1e-6, max_iter=1000, verbose=False)\n",
    "time_monotone = vfi_monotone.timing_info['elapsed']\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Method':<35} {'Time (s)':>12} {'Speedup':>12}\")\n",
    "print(\"-\"*60)\n",
    "print(f\"{'Standard VFI':<35} {time_standard:>12.3f} {'1.0x':>12}\")\n",
    "print(f\"{'VFI + Howard':<35} {time_howard:>12.3f} {time_standard/time_howard:>11.1f}x\")\n",
    "print(f\"{'VFI + Howard + Monotonicity':<35} {time_monotone:>12.3f} {time_standard/time_monotone:>11.1f}x\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Endogenous Grid Method (EGM)\n",
    "\n",
    "## 2.1 The Key Insight\n",
    "\n",
    "**The Problem with Standard Methods**: At each state $(k, z)$, we search for optimal $k'$. This requires evaluating many candidate $k'$ values.\n",
    "\n",
    "**EGM's Inversion**: Instead of asking \"given $k$, what is optimal $k'$?\", EGM asks \"given $k'$, what $k$ would make this $k'$ optimal?\"\n",
    "\n",
    "**The Algorithm:**\n",
    "1. Fix a grid of **next-period capital** $k'$ values\n",
    "2. For each $(k', z)$:\n",
    "   - Compute expected marginal value: $E[u'(c') \\cdot R']$\n",
    "   - Use Euler equation to find current $c$: $c = (\\beta E[\\cdot])^{-1/\\sigma}$\n",
    "   - Back out current $k$: $k = (c + k' - (1-\\delta)k) / (zk^{\\alpha-1})$ ‚Üí solve for $k$\n",
    "3. This gives us pairs $(k, c)$ for each $k'$ ‚Äî an **endogenous** grid!\n",
    "4. Interpolate to get $c(k)$ on our original grid\n",
    "\n",
    "**Key Advantage**: No optimization step! The Euler equation is solved analytically."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# 2.2 EGM Implementation\n",
    "# =============================================================================\n",
    "\n",
    "class EGMSolver:\n",
    "    \"\"\"\n",
    "    Endogenous Grid Method for the RBC model.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        \n",
    "        # Initialize consumption policy\n",
    "        self.policy_c = np.zeros((model.n_k, model.n_z))\n",
    "        for i_k, k in enumerate(model.k_grid):\n",
    "            for i_z, z in enumerate(model.z_grid):\n",
    "                resources = z * k**model.alpha + (1 - model.delta) * k\n",
    "                self.policy_c[i_k, i_z] = 0.5 * resources\n",
    "        \n",
    "        # Grid for k' (next period capital) - same as k grid\n",
    "        self.kp_grid = model.k_grid.copy()\n",
    "        \n",
    "        self.convergence_history = []\n",
    "        self.timing_info = {}\n",
    "        \n",
    "    def _egm_step(self):\n",
    "        \"\"\"\n",
    "        One iteration of EGM.\n",
    "        \"\"\"\n",
    "        # Storage for endogenous grid and consumption\n",
    "        k_endo = np.zeros((self.model.n_k, self.model.n_z))\n",
    "        c_endo = np.zeros((self.model.n_k, self.model.n_z))\n",
    "        \n",
    "        for i_z, z in enumerate(self.model.z_grid):\n",
    "            for i_kp, kp in enumerate(self.kp_grid):\n",
    "                \n",
    "                # Step 1: Compute expected marginal utility * return\n",
    "                rhs = 0.0\n",
    "                for i_zp, zp in enumerate(self.model.z_grid):\n",
    "                    # Next period consumption from current policy\n",
    "                    cp = np.interp(kp, self.model.k_grid, self.policy_c[:, i_zp])\n",
    "                    cp = max(cp, 1e-10)\n",
    "                    \n",
    "                    # Gross return\n",
    "                    Rp = self.model.gross_return(kp, zp)\n",
    "                    \n",
    "                    # Expected value\n",
    "                    rhs += self.model.Pi[i_z, i_zp] * self.model.marginal_utility(cp) * Rp\n",
    "                \n",
    "                # Step 2: Current consumption from Euler equation\n",
    "                c = self.model.inv_marginal_utility(self.model.beta * rhs)\n",
    "                \n",
    "                # Step 3: Back out current k from budget constraint\n",
    "                # c + kp = z * k^alpha + (1-delta) * k\n",
    "                # This is implicit in k, so we solve numerically\n",
    "                def budget_residual(k):\n",
    "                    if k <= 0:\n",
    "                        return np.inf\n",
    "                    resources = z * k**self.model.alpha + (1 - self.model.delta) * k\n",
    "                    return resources - c - kp\n",
    "                \n",
    "                # Find k that satisfies budget constraint\n",
    "                try:\n",
    "                    k_solved = brentq(budget_residual, 1e-6, self.model.k_grid[-1] * 2)\n",
    "                except:\n",
    "                    k_solved = self.model.k_grid[i_kp]  # Fallback\n",
    "                \n",
    "                k_endo[i_kp, i_z] = k_solved\n",
    "                c_endo[i_kp, i_z] = c\n",
    "        \n",
    "        # Step 4: Interpolate back to original grid\n",
    "        policy_c_new = np.zeros_like(self.policy_c)\n",
    "        \n",
    "        for i_z in range(self.model.n_z):\n",
    "            # Sort endogenous grid\n",
    "            sort_idx = np.argsort(k_endo[:, i_z])\n",
    "            k_sorted = k_endo[sort_idx, i_z]\n",
    "            c_sorted = c_endo[sort_idx, i_z]\n",
    "            \n",
    "            # Remove duplicates and interpolate\n",
    "            unique_mask = np.concatenate([[True], np.diff(k_sorted) > 1e-10])\n",
    "            k_unique = k_sorted[unique_mask]\n",
    "            c_unique = c_sorted[unique_mask]\n",
    "            \n",
    "            if len(k_unique) > 1:\n",
    "                policy_c_new[:, i_z] = np.interp(\n",
    "                    self.model.k_grid, k_unique, c_unique,\n",
    "                    left=c_unique[0], right=c_unique[-1]\n",
    "                )\n",
    "            else:\n",
    "                policy_c_new[:, i_z] = self.policy_c[:, i_z]\n",
    "        \n",
    "        return policy_c_new\n",
    "    \n",
    "    def solve(self, tol=1e-8, max_iter=500, verbose=True):\n",
    "        \"\"\"\n",
    "        Solve using EGM.\n",
    "        \"\"\"\n",
    "        print(\"\\n=== Endogenous Grid Method (EGM) ===\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for iteration in range(max_iter):\n",
    "            policy_c_old = self.policy_c.copy()\n",
    "            \n",
    "            self.policy_c = self._egm_step()\n",
    "            \n",
    "            # Check convergence\n",
    "            diff = np.max(np.abs(self.policy_c - policy_c_old))\n",
    "            self.convergence_history.append(diff)\n",
    "            \n",
    "            if verbose and iteration % 20 == 0:\n",
    "                print(f\"Iteration {iteration:4d}: ||c - c_old|| = {diff:.2e}\")\n",
    "            \n",
    "            if diff < tol:\n",
    "                elapsed = time.time() - start_time\n",
    "                self.timing_info['elapsed'] = elapsed\n",
    "                self.timing_info['iterations'] = iteration + 1\n",
    "                print(f\"\\nConverged in {iteration+1} iterations ({elapsed:.2f} seconds)\")\n",
    "                return True\n",
    "        \n",
    "        print(f\"\\nWARNING: Did not converge after {max_iter} iterations\")\n",
    "        return False\n",
    "    \n",
    "    def get_policy_k(self):\n",
    "        \"\"\"Compute capital policy from consumption policy.\"\"\"\n",
    "        policy_k = np.zeros_like(self.policy_c)\n",
    "        for i_k, k in enumerate(self.model.k_grid):\n",
    "            for i_z, z in enumerate(self.model.z_grid):\n",
    "                resources = z * k**self.model.alpha + (1 - self.model.delta) * k\n",
    "                policy_k[i_k, i_z] = resources - self.policy_c[i_k, i_z]\n",
    "        return policy_k"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Solve with EGM\n",
    "egm_solver = EGMSolver(model)\n",
    "egm_solver.solve(tol=1e-7, max_iter=200, verbose=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Compare EGM with VFI\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "i_z_mid = model.n_z // 2\n",
    "egm_policy_k = egm_solver.get_policy_k()\n",
    "vfi_policy_k = vfi_howard.get_policy_k()\n",
    "\n",
    "# Consumption policy\n",
    "axes[0].plot(model.k_grid, vfi_howard.policy_c[:, i_z_mid], 'b-', \n",
    "             label='VFI + Howard', linewidth=2)\n",
    "axes[0].plot(model.k_grid, egm_solver.policy_c[:, i_z_mid], 'r--', \n",
    "             label='EGM', linewidth=2)\n",
    "axes[0].set_xlabel('Capital (k)')\n",
    "axes[0].set_ylabel('Consumption')\n",
    "axes[0].set_title('Consumption Policy')\n",
    "axes[0].legend()\n",
    "\n",
    "# Capital policy\n",
    "axes[1].plot(model.k_grid, vfi_policy_k[:, i_z_mid], 'b-', \n",
    "             label='VFI + Howard', linewidth=2)\n",
    "axes[1].plot(model.k_grid, egm_policy_k[:, i_z_mid], 'r--', \n",
    "             label='EGM', linewidth=2)\n",
    "axes[1].plot(model.k_grid, model.k_grid, 'k:', alpha=0.3)\n",
    "axes[1].set_xlabel('Capital (k)')\n",
    "axes[1].set_ylabel(\"k'\")\n",
    "axes[1].set_title('Capital Policy')\n",
    "axes[1].legend()\n",
    "\n",
    "# Difference\n",
    "diff_c = egm_solver.policy_c[:, i_z_mid] - vfi_howard.policy_c[:, i_z_mid]\n",
    "axes[2].plot(model.k_grid, diff_c * 100, 'g-', linewidth=2)\n",
    "axes[2].axhline(0, color='gray', linestyle='--', alpha=0.5)\n",
    "axes[2].set_xlabel('Capital (k)')\n",
    "axes[2].set_ylabel('Difference (%)')\n",
    "axes[2].set_title('Policy Difference (EGM - VFI)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Accuracy Assessment with Euler Equation Errors\n",
    "\n",
    "## 3.1 The Euler Equation Error\n",
    "\n",
    "The Euler equation must hold exactly for the true policy:\n",
    "\n",
    "$$u'(c(k,z)) = \\beta E\\left[ u'(c(k',z')) \\cdot R(k',z') \\right]$$\n",
    "\n",
    "For an approximate policy, define the **Euler equation residual**:\n",
    "\n",
    "$$\\varepsilon(k,z) = 1 - \\frac{\\beta E\\left[ u'(c(k',z')) \\cdot R(k',z') \\right]}{u'(c(k,z))}$$\n",
    "\n",
    "**Interpretation**: $\\varepsilon$ measures the \"mistake\" in units of consumption. If $\\varepsilon = 10^{-3}$, the agent makes a $0.1\\%$ consumption error.\n",
    "\n",
    "**Reporting Convention**: Report $\\log_{10}|\\varepsilon|$\n",
    "- $-3$ means $0.1\\%$ error\n",
    "- $-4$ means $0.01\\%$ error\n",
    "- $-6$ means \"machine precision\""
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# 3.2 Euler Equation Error Calculator\n",
    "# =============================================================================\n",
    "\n",
    "class EulerErrorCalculator:\n",
    "    \"\"\"\n",
    "    Computes Euler equation errors for accuracy assessment.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, policy_c):\n",
    "        self.model = model\n",
    "        self.policy_c = policy_c\n",
    "        \n",
    "    def compute_errors(self, n_test=1000, seed=42):\n",
    "        \"\"\"\n",
    "        Compute Euler errors at random test points.\n",
    "        \n",
    "        Returns array of log10(|euler_error|).\n",
    "        \"\"\"\n",
    "        np.random.seed(seed)\n",
    "        \n",
    "        # Random test points\n",
    "        k_test = np.random.uniform(self.model.k_grid[0], self.model.k_grid[-1], n_test)\n",
    "        z_idx_test = np.random.randint(0, self.model.n_z, n_test)\n",
    "        \n",
    "        errors = np.zeros(n_test)\n",
    "        \n",
    "        for i in range(n_test):\n",
    "            k = k_test[i]\n",
    "            i_z = z_idx_test[i]\n",
    "            z = self.model.z_grid[i_z]\n",
    "            \n",
    "            # Current consumption (interpolated)\n",
    "            c = np.interp(k, self.model.k_grid, self.policy_c[:, i_z])\n",
    "            c = max(c, 1e-10)\n",
    "            \n",
    "            # Next period capital\n",
    "            resources = z * k**self.model.alpha + (1 - self.model.delta) * k\n",
    "            kp = resources - c\n",
    "            kp = np.clip(kp, self.model.k_grid[0], self.model.k_grid[-1])\n",
    "            \n",
    "            # Expected RHS of Euler equation\n",
    "            euler_rhs = 0.0\n",
    "            for i_zp in range(self.model.n_z):\n",
    "                zp = self.model.z_grid[i_zp]\n",
    "                cp = np.interp(kp, self.model.k_grid, self.policy_c[:, i_zp])\n",
    "                cp = max(cp, 1e-10)\n",
    "                \n",
    "                Rp = self.model.gross_return(kp, zp)\n",
    "                euler_rhs += self.model.Pi[i_z, i_zp] * self.model.marginal_utility(cp) * Rp\n",
    "            \n",
    "            euler_rhs *= self.model.beta\n",
    "            \n",
    "            # Euler error\n",
    "            euler_lhs = self.model.marginal_utility(c)\n",
    "            error = 1 - euler_rhs / euler_lhs\n",
    "            \n",
    "            errors[i] = np.log10(max(abs(error), 1e-16))\n",
    "        \n",
    "        return errors, k_test, z_idx_test\n",
    "    \n",
    "    def compute_errors_on_grid(self):\n",
    "        \"\"\"\n",
    "        Compute Euler errors on the full grid.\n",
    "        \"\"\"\n",
    "        errors = np.zeros((self.model.n_k, self.model.n_z))\n",
    "        \n",
    "        for i_k, k in enumerate(self.model.k_grid):\n",
    "            for i_z, z in enumerate(self.model.z_grid):\n",
    "                c = self.policy_c[i_k, i_z]\n",
    "                c = max(c, 1e-10)\n",
    "                \n",
    "                resources = z * k**self.model.alpha + (1 - self.model.delta) * k\n",
    "                kp = resources - c\n",
    "                kp = np.clip(kp, self.model.k_grid[0], self.model.k_grid[-1])\n",
    "                \n",
    "                euler_rhs = 0.0\n",
    "                for i_zp in range(self.model.n_z):\n",
    "                    zp = self.model.z_grid[i_zp]\n",
    "                    cp = np.interp(kp, self.model.k_grid, self.policy_c[:, i_zp])\n",
    "                    cp = max(cp, 1e-10)\n",
    "                    Rp = self.model.gross_return(kp, zp)\n",
    "                    euler_rhs += self.model.Pi[i_z, i_zp] * self.model.marginal_utility(cp) * Rp\n",
    "                \n",
    "                euler_rhs *= self.model.beta\n",
    "                euler_lhs = self.model.marginal_utility(c)\n",
    "                error = 1 - euler_rhs / euler_lhs\n",
    "                \n",
    "                errors[i_k, i_z] = np.log10(max(abs(error), 1e-16))\n",
    "        \n",
    "        return errors"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Compute Euler errors for both methods\n",
    "ee_vfi = EulerErrorCalculator(model, vfi_howard.policy_c)\n",
    "ee_egm = EulerErrorCalculator(model, egm_solver.policy_c)\n",
    "\n",
    "errors_vfi, k_test, z_test = ee_vfi.compute_errors(n_test=5000)\n",
    "errors_egm, _, _ = ee_egm.compute_errors(n_test=5000)\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EULER EQUATION ERRORS (log10 scale)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Method':<20} {'Mean':>12} {'Max':>12} {'Min':>12}\")\n",
    "print(\"-\"*60)\n",
    "print(f\"{'VFI + Howard':<20} {np.mean(errors_vfi):>12.2f} {np.max(errors_vfi):>12.2f} {np.min(errors_vfi):>12.2f}\")\n",
    "print(f\"{'EGM':<20} {np.mean(errors_egm):>12.2f} {np.max(errors_egm):>12.2f} {np.min(errors_egm):>12.2f}\")\n",
    "print(\"\\nInterpretation: -3 = 0.1% error, -4 = 0.01% error\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Visualize Euler errors\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Histogram comparison\n",
    "axes[0, 0].hist(errors_vfi, bins=50, alpha=0.7, label='VFI + Howard', density=True)\n",
    "axes[0, 0].hist(errors_egm, bins=50, alpha=0.7, label='EGM', density=True)\n",
    "axes[0, 0].axvline(-3, color='red', linestyle='--', label='0.1% error')\n",
    "axes[0, 0].axvline(-4, color='green', linestyle='--', label='0.01% error')\n",
    "axes[0, 0].set_xlabel('log‚ÇÅ‚ÇÄ|Euler Error|')\n",
    "axes[0, 0].set_ylabel('Density')\n",
    "axes[0, 0].set_title('Distribution of Euler Errors')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# Errors on grid (VFI)\n",
    "errors_grid_vfi = ee_vfi.compute_errors_on_grid()\n",
    "im1 = axes[0, 1].imshow(errors_grid_vfi.T, aspect='auto', origin='lower',\n",
    "                         extent=[model.k_grid[0], model.k_grid[-1], 0, model.n_z-1],\n",
    "                         cmap='RdYlGn_r', vmin=-6, vmax=-2)\n",
    "axes[0, 1].set_xlabel('Capital (k)')\n",
    "axes[0, 1].set_ylabel('Productivity State (z index)')\n",
    "axes[0, 1].set_title('Euler Errors: VFI + Howard')\n",
    "plt.colorbar(im1, ax=axes[0, 1], label='log‚ÇÅ‚ÇÄ|error|')\n",
    "\n",
    "# Errors on grid (EGM)\n",
    "errors_grid_egm = ee_egm.compute_errors_on_grid()\n",
    "im2 = axes[1, 0].imshow(errors_grid_egm.T, aspect='auto', origin='lower',\n",
    "                         extent=[model.k_grid[0], model.k_grid[-1], 0, model.n_z-1],\n",
    "                         cmap='RdYlGn_r', vmin=-6, vmax=-2)\n",
    "axes[1, 0].set_xlabel('Capital (k)')\n",
    "axes[1, 0].set_ylabel('Productivity State (z index)')\n",
    "axes[1, 0].set_title('Euler Errors: EGM')\n",
    "plt.colorbar(im2, ax=axes[1, 0], label='log‚ÇÅ‚ÇÄ|error|')\n",
    "\n",
    "# Error by capital level\n",
    "axes[1, 1].plot(model.k_grid, errors_grid_vfi[:, model.n_z//2], 'b-', \n",
    "                label='VFI + Howard', linewidth=2)\n",
    "axes[1, 1].plot(model.k_grid, errors_grid_egm[:, model.n_z//2], 'r--', \n",
    "                label='EGM', linewidth=2)\n",
    "axes[1, 1].axhline(-3, color='gray', linestyle=':', alpha=0.5)\n",
    "axes[1, 1].axhline(-4, color='gray', linestyle=':', alpha=0.5)\n",
    "axes[1, 1].set_xlabel('Capital (k)')\n",
    "axes[1, 1].set_ylabel('log‚ÇÅ‚ÇÄ|Euler Error|')\n",
    "axes[1, 1].set_title('Euler Errors at Median Productivity')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Sensitivity Analysis\n",
    "\n",
    "## 4.1 How Do Numerical Choices Affect Results?\n",
    "\n",
    "Key questions:\n",
    "1. **Grid density**: How many points do we need?\n",
    "2. **Tolerance**: How tight should convergence be?\n",
    "3. **Interpolation**: Linear vs. cubic vs. higher-order?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# 4.2 Grid Density Analysis\n",
    "# =============================================================================\n",
    "\n",
    "grid_sizes = [25, 50, 100, 200, 400]\n",
    "results_grid = []\n",
    "\n",
    "print(\"\\nGrid Density Analysis\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for n_k in grid_sizes:\n",
    "    # Create model with different grid size\n",
    "    model_test = RBCModel(n_k=n_k, n_z=7)\n",
    "    \n",
    "    # Solve with VFI + Howard\n",
    "    vfi_test = VFIHoward(model_test, howard_steps=20)\n",
    "    vfi_test.solve(tol=1e-7, max_iter=500, verbose=False)\n",
    "    \n",
    "    # Compute Euler errors\n",
    "    ee_test = EulerErrorCalculator(model_test, vfi_test.policy_c)\n",
    "    errors, _, _ = ee_test.compute_errors(n_test=2000)\n",
    "    \n",
    "    results_grid.append({\n",
    "        'n_k': n_k,\n",
    "        'time': vfi_test.timing_info['elapsed'],\n",
    "        'mean_error': np.mean(errors),\n",
    "        'max_error': np.max(errors)\n",
    "    })\n",
    "    \n",
    "    print(f\"n_k={n_k:4d}: time={vfi_test.timing_info['elapsed']:.2f}s, \"\n",
    "          f\"mean error={np.mean(errors):.2f}, max error={np.max(errors):.2f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Visualize grid density tradeoffs\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "grid_sizes_arr = np.array([r['n_k'] for r in results_grid])\n",
    "times = np.array([r['time'] for r in results_grid])\n",
    "mean_errors = np.array([r['mean_error'] for r in results_grid])\n",
    "max_errors = np.array([r['max_error'] for r in results_grid])\n",
    "\n",
    "# Time vs Grid Size\n",
    "axes[0].loglog(grid_sizes_arr, times, 'bo-', markersize=10, linewidth=2)\n",
    "axes[0].set_xlabel('Number of Grid Points')\n",
    "axes[0].set_ylabel('Solution Time (seconds)')\n",
    "axes[0].set_title('Computational Cost vs Grid Density')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy vs Grid Size\n",
    "axes[1].semilogx(grid_sizes_arr, mean_errors, 'b-o', markersize=10, linewidth=2, label='Mean Error')\n",
    "axes[1].semilogx(grid_sizes_arr, max_errors, 'r-s', markersize=10, linewidth=2, label='Max Error')\n",
    "axes[1].axhline(-3, color='gray', linestyle='--', alpha=0.5, label='0.1% threshold')\n",
    "axes[1].axhline(-4, color='gray', linestyle=':', alpha=0.5, label='0.01% threshold')\n",
    "axes[1].set_xlabel('Number of Grid Points')\n",
    "axes[1].set_ylabel('log‚ÇÅ‚ÇÄ|Euler Error|')\n",
    "axes[1].set_title('Accuracy vs Grid Density')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5: Impulse Response Analysis\n",
    "\n",
    "## 5.1 Economic Plausibility Check\n",
    "\n",
    "A good numerical solution should produce economically sensible impulse responses:\n",
    "- Positive productivity shock ‚Üí Output, consumption, investment all rise\n",
    "- Consumption smoother than output\n",
    "- Investment more volatile than output\n",
    "- Gradual return to steady state"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# 5.2 Impulse Response Function Generator\n",
    "# =============================================================================\n",
    "\n",
    "def compute_irf(model, policy_c, shock_size=1, T=40):\n",
    "    \"\"\"\n",
    "    Compute impulse response to a one-standard-deviation productivity shock.\n",
    "    \n",
    "    shock_size: number of grid points to move from median\n",
    "    \"\"\"\n",
    "    # Baseline path (no shock)\n",
    "    k_base = np.zeros(T+1)\n",
    "    y_base = np.zeros(T)\n",
    "    c_base = np.zeros(T)\n",
    "    i_base = np.zeros(T)\n",
    "    \n",
    "    k_base[0] = model.k_ss\n",
    "    z_idx_base = model.n_z // 2  # Median productivity\n",
    "    \n",
    "    for t in range(T):\n",
    "        k = k_base[t]\n",
    "        z = model.z_grid[z_idx_base]\n",
    "        \n",
    "        c = np.interp(k, model.k_grid, policy_c[:, z_idx_base])\n",
    "        y = z * k ** model.alpha\n",
    "        resources = y + (1 - model.delta) * k\n",
    "        kp = resources - c\n",
    "        \n",
    "        y_base[t] = y\n",
    "        c_base[t] = c\n",
    "        i_base[t] = kp - (1 - model.delta) * k\n",
    "        k_base[t+1] = kp\n",
    "    \n",
    "    # Shocked path\n",
    "    k_shock = np.zeros(T+1)\n",
    "    y_shock = np.zeros(T)\n",
    "    c_shock = np.zeros(T)\n",
    "    i_shock = np.zeros(T)\n",
    "    z_idx_shock = np.zeros(T, dtype=int)\n",
    "    \n",
    "    k_shock[0] = model.k_ss\n",
    "    z_idx_shock[0] = min(model.n_z // 2 + shock_size, model.n_z - 1)  # Positive shock\n",
    "    \n",
    "    for t in range(T):\n",
    "        k = k_shock[t]\n",
    "        z_idx = z_idx_shock[t]\n",
    "        z = model.z_grid[z_idx]\n",
    "        \n",
    "        c = np.interp(k, model.k_grid, policy_c[:, z_idx])\n",
    "        y = z * k ** model.alpha\n",
    "        resources = y + (1 - model.delta) * k\n",
    "        kp = resources - c\n",
    "        \n",
    "        y_shock[t] = y\n",
    "        c_shock[t] = c\n",
    "        i_shock[t] = kp - (1 - model.delta) * k\n",
    "        k_shock[t+1] = kp\n",
    "        \n",
    "        # Productivity reverts to mean (deterministically for clean IRF)\n",
    "        if t < T - 1:\n",
    "            # Expected next z index (mean reversion)\n",
    "            expected_log_z = model.rho * model.log_z_grid[z_idx]\n",
    "            z_idx_shock[t+1] = np.argmin(np.abs(model.log_z_grid - expected_log_z))\n",
    "    \n",
    "    # Compute percentage deviations from baseline\n",
    "    irf = {\n",
    "        'Y': 100 * (y_shock / y_base - 1),\n",
    "        'C': 100 * (c_shock / c_base - 1),\n",
    "        'I': 100 * (i_shock / i_base - 1),\n",
    "        'K': 100 * (k_shock[:-1] / k_base[:-1] - 1),\n",
    "        'z': model.z_grid[z_idx_shock]\n",
    "    }\n",
    "    \n",
    "    return irf"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Compute and plot IRFs\n",
    "irf_vfi = compute_irf(model, vfi_howard.policy_c, shock_size=2, T=40)\n",
    "irf_egm = compute_irf(model, egm_solver.policy_c, shock_size=2, T=40)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "T = len(irf_vfi['Y'])\n",
    "periods = np.arange(T)\n",
    "\n",
    "# Output\n",
    "axes[0, 0].plot(periods, irf_vfi['Y'], 'b-', label='VFI + Howard', linewidth=2)\n",
    "axes[0, 0].plot(periods, irf_egm['Y'], 'r--', label='EGM', linewidth=2)\n",
    "axes[0, 0].axhline(0, color='gray', linestyle=':', alpha=0.5)\n",
    "axes[0, 0].set_xlabel('Periods after shock')\n",
    "axes[0, 0].set_ylabel('% deviation from baseline')\n",
    "axes[0, 0].set_title('Output Response')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# Consumption\n",
    "axes[0, 1].plot(periods, irf_vfi['C'], 'b-', label='VFI + Howard', linewidth=2)\n",
    "axes[0, 1].plot(periods, irf_egm['C'], 'r--', label='EGM', linewidth=2)\n",
    "axes[0, 1].axhline(0, color='gray', linestyle=':', alpha=0.5)\n",
    "axes[0, 1].set_xlabel('Periods after shock')\n",
    "axes[0, 1].set_ylabel('% deviation from baseline')\n",
    "axes[0, 1].set_title('Consumption Response')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# Investment\n",
    "axes[1, 0].plot(periods, irf_vfi['I'], 'b-', label='VFI + Howard', linewidth=2)\n",
    "axes[1, 0].plot(periods, irf_egm['I'], 'r--', label='EGM', linewidth=2)\n",
    "axes[1, 0].axhline(0, color='gray', linestyle=':', alpha=0.5)\n",
    "axes[1, 0].set_xlabel('Periods after shock')\n",
    "axes[1, 0].set_ylabel('% deviation from baseline')\n",
    "axes[1, 0].set_title('Investment Response')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# Capital\n",
    "axes[1, 1].plot(periods, irf_vfi['K'], 'b-', label='VFI + Howard', linewidth=2)\n",
    "axes[1, 1].plot(periods, irf_egm['K'], 'r--', label='EGM', linewidth=2)\n",
    "axes[1, 1].axhline(0, color='gray', linestyle=':', alpha=0.5)\n",
    "axes[1, 1].set_xlabel('Periods after shock')\n",
    "axes[1, 1].set_ylabel('% deviation from baseline')\n",
    "axes[1, 1].set_title('Capital Response')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nEconomic Plausibility Checks:\")\n",
    "print(f\"‚úì Output rises on impact: {irf_vfi['Y'][0]:.2f}%\")\n",
    "print(f\"‚úì Consumption smoother: max C response = {max(irf_vfi['C']):.2f}% < max Y = {max(irf_vfi['Y']):.2f}%\")\n",
    "print(f\"‚úì Investment more volatile: max I response = {max(irf_vfi['I']):.2f}%\")\n",
    "print(f\"‚úì Gradual convergence: Y at t=20 = {irf_vfi['Y'][20]:.2f}%\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary and Key Takeaways\n",
    "\n",
    "## What We Learned\n",
    "\n",
    "### Part 1: Accelerating VFI\n",
    "- **Howard's Policy Improvement**: Dramatically reduces computation time (10-100x speedup)\n",
    "- **Monotonicity**: Further gains by exploiting economic structure\n",
    "- **Key insight**: The policy converges faster than the value function\n",
    "\n",
    "### Part 2: Endogenous Grid Method\n",
    "- **Eliminates optimization**: Transforms the problem from finding optimal $k'$ to inverting the Euler equation\n",
    "- **Trade-off**: Requires solving for endogenous grid points\n",
    "- **Best for**: Models with well-behaved Euler equations\n",
    "\n",
    "### Part 3: Accuracy Assessment\n",
    "- **Euler equation errors**: The gold standard for accuracy measurement\n",
    "- **Interpretation**: $\\log_{10}$ scale makes errors comparable\n",
    "- **Target**: Mean errors below $-3$ (0.1% consumption error) for most applications\n",
    "\n",
    "### Part 4: Sensitivity Analysis\n",
    "- **Grid density**: Diminishing returns beyond ~100-200 points for simple models\n",
    "- **Trade-off**: Computational cost grows faster than accuracy improves\n",
    "\n",
    "### Part 5: Impulse Responses\n",
    "- **Economic validation**: Does the solution make economic sense?\n",
    "- **Key patterns**: Consumption smoothing, investment volatility, mean reversion\n",
    "\n",
    "---\n",
    "\n",
    "## Looking Ahead (Lab 9)\n",
    "\n",
    "Next lab: **Perturbation and Projection Methods**\n",
    "- Linear and higher-order perturbation around steady state\n",
    "- Projection methods (Galerkin, collocation)\n",
    "- When to use which method\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Research Architect Reflection\n",
    "\n",
    "Today we demonstrated the full validation pipeline:\n",
    "\n",
    "1. **Speed**: Does the algorithm run fast enough? (Timing comparisons)\n",
    "2. **Accuracy**: Are the results numerically precise? (Euler equation errors)\n",
    "3. **Robustness**: Do results depend on numerical choices? (Sensitivity analysis)\n",
    "4. **Economic Sense**: Are the results plausible? (Impulse responses)\n",
    "\n",
    "A Research Architect's value lies in knowing **which questions to ask** and **how to interpret answers**. The implementation is increasingly automatable; the judgment is not."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
