{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Krusell and Smith (1998) with Deep Equilibrium Nets (PyTorch Version)\n",
    "\n",
    "This notebook solves the classic heterogeneous agent model from Krusell and Smith (1998) using the **Deep Equilibrium Net (DEQN)** method (Azinovic, Gaegauf, and Scheidegger, 2022).\n",
    "\n",
    "**Framework Adaptation:**\n",
    "This is a port of the original implementation by Jan Žemlička. While the original used Google JAX, this version is rewritten using **PyTorch**. \n",
    "\n",
    "**Methodology:**\n",
    "1. **Calibration (SSJ):** We use the `sequence-jacobian` toolbox (which uses JAX) to compute the steady state and calibrate grids. This is the most efficient way to initialize the model.\n",
    "2. **Deep Learning (PyTorch):** We convert the steady-state objects to PyTorch tensors and use a PyTorch neural network to solve the global dynamics (Global Solution).\n",
    "\n",
    "**Hardware:**\n",
    "A GPU is highly recommended for the distribution transport steps."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Install dependencies\n",
    "# We need jax/sequence-jacobian for initialization, and torch for the solution.\n",
    "!pip install sequence-jacobian jax jaxlib\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install matplotlib scipy"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sequence_jacobian as ssj\n",
    "import time\n",
    "import copy\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set precision to float32 (standard for DL) or float64 (standard for Econ)\n",
    "# float32 is usually sufficient for DEQN and much faster on consumer GPUs\n",
    "torch.set_default_dtype(torch.float32)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Initialization via Sequence-Jacobian\n",
    "We use the standard SSJ toolbox to solve for the steady state. This ensures our grids and parameters are economically valid before we start training the neural net."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "''' Define the SSJ Blocks (Standard Economics Logic) '''\n",
    "\n",
    "# 1. Household Block\n",
    "def household_init(a_grid, e_grid, r, w, eis):\n",
    "    coh = (1 + r) * a_grid[np.newaxis, :] + w * e_grid[:, np.newaxis]\n",
    "    Va = (1 + r) * (0.1 * coh) ** (-1 / eis)\n",
    "    return Va\n",
    "\n",
    "def make_grid(rho_e, sd_e, nE, amin, amax, nA):\n",
    "    e_grid, pi_e, Pi = ssj.grids.markov_rouwenhorst(rho=rho_e, sigma=sd_e, N=nE)\n",
    "    a_grid = ssj.grids.agrid(amin=amin, amax=amax, n=nA)\n",
    "    return e_grid, Pi, a_grid, pi_e\n",
    "\n",
    "@ssj.het(exogenous='Pi', policy='a', backward='Va', backward_init=household_init)\n",
    "def household(Va_p, a_grid, e_grid, r, w, beta, eis):\n",
    "    uc_nextgrid = beta * Va_p\n",
    "    c_nextgrid = uc_nextgrid ** (-eis)\n",
    "    coh = (1 + r) * a_grid[np.newaxis, :] + w * e_grid[:, np.newaxis]\n",
    "    a = ssj.interpolate.interpolate_y(c_nextgrid + a_grid, coh, a_grid)\n",
    "    ssj.misc.setmin(a, a_grid[0])\n",
    "    c = coh - a\n",
    "    Va = (1 + r) * c ** (-1 / eis)\n",
    "    return Va, a, c\n",
    "\n",
    "household = household.add_hetinputs([make_grid])\n",
    "\n",
    "# 2. Firm and Market Clearing\n",
    "@ssj.simple\n",
    "def firm(K, L, Z, alpha, delta):\n",
    "    r = alpha * Z * (K(-1) / L) ** (alpha-1) - delta\n",
    "    w = (1 - alpha) * Z * (K(-1) / L) ** alpha\n",
    "    Y = Z * K(-1) ** alpha * L ** (1 - alpha)\n",
    "    return r, w, Y\n",
    "\n",
    "@ssj.simple\n",
    "def mkt_clearing(K, A, Y, C, delta):\n",
    "    asset_mkt = A - K\n",
    "    goods_mkt = Y - C - delta * K\n",
    "    return asset_mkt, goods_mkt\n",
    "\n",
    "# 3. Solve Steady State\n",
    "ks_model = ssj.create_model([household, firm, mkt_clearing], name='Krusell-Smith')\n",
    "\n",
    "calibration = {'eis': 0.5, 'delta': 0.025, 'alpha': 0.36, 'rho_e': 0.966, 'sd_e': 0.5, 'L': 1.0,\n",
    "               'nE': 3, 'nA': 100, 'amin': 0, 'amax': 50, 'Z': 1.0, 'beta': 0.98}\n",
    "unknowns_ss = {'K': 30.}\n",
    "targets_ss = {'asset_mkt': 0.}\n",
    "\n",
    "print(\"Solving for Steady State...\")\n",
    "ks_steady = ks_model.solve_steady_state(calibration, unknowns_ss, targets_ss, solver='hybr')\n",
    "print(f\"Steady State Capital (K): {ks_steady['K']:.4f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Extract grids and transition matrices to Numpy\n",
    "# We will convert these to PyTorch tensors shortly\n",
    "ss_a_grid = ks_steady.internals['household']['a_grid']\n",
    "ss_e_grid = ks_steady.internals['household']['e_grid']\n",
    "ss_Pi_e = ks_steady.internals['household']['Pi'] # Transition matrix for idiosyncratic shock\n",
    "ss_dist = ks_steady.internals['household']['D'].T  # Stationary distribution\n",
    "ss_K = ks_steady['K']\n",
    "\n",
    "# Define TFP Process (Aggregate Shock)\n",
    "rho_tfp = 0.9\n",
    "sigma_tfp = 0.007\n",
    "n_tfp = 5\n",
    "tfp_grid, pi_tfp, Pi_tfp = ssj.grids.markov_tauchen(rho=rho_tfp, sigma=sigma_tfp, N=n_tfp)\n",
    "tfp_grid = np.exp(tfp_grid) # Levels, not logs"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: PyTorch Implementation (DEQN)\n",
    "\n",
    "Here we define the Neural Network and the Physics of the model (Transition Dynamics) using PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "class KS_Network(nn.Module):\n",
    "    def __init__(self, n_input, n_hidden=128, n_out=1):\n",
    "        super().__init__()\n",
    "        # Deep Equilibrium Net Architecture\n",
    "        # Input: [Idiosyncratic State, Aggregate State]\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_input, n_hidden),\n",
    "            nn.Mish(), # Mish activation helps with smooth gradients in Econ models\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.Mish(),\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.Mish(),\n",
    "            nn.Linear(n_hidden, n_out)\n",
    "        )\n",
    "        \n",
    "        # Initialize weights using Xavier uniform (good for Tanh/Sigmoid/Mish)\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            if m.bias is not None:\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Output is logit of savings rate\n",
    "        return self.net(x)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "class KrusellSmithModel:\n",
    "    def __init__(self, calibration, steady_state_data, tfp_data, device):\n",
    "        self.device = device\n",
    "        \n",
    "        # Unpack parameters\n",
    "        self.beta = calibration['beta']\n",
    "        self.gamma = 1 / calibration['eis']\n",
    "        self.alpha = calibration['alpha']\n",
    "        self.delta = calibration['delta']\n",
    "        self.amin = calibration['amin']\n",
    "        self.amax = calibration['amax']\n",
    "        \n",
    "        # Convert Grids to Tensors\n",
    "        self.a_grid = torch.tensor(steady_state_data['a_grid'], dtype=torch.float32, device=device)\n",
    "        self.e_grid = torch.tensor(steady_state_data['e_grid'], dtype=torch.float32, device=device)\n",
    "        self.Pi_e = torch.tensor(steady_state_data['Pi_e'], dtype=torch.float32, device=device)\n",
    "        \n",
    "        # TFP Process\n",
    "        self.tfp_grid = torch.tensor(tfp_data['grid'], dtype=torch.float32, device=device)\n",
    "        self.Pi_tfp = torch.tensor(tfp_data['Pi'], dtype=torch.float32, device=device)\n",
    "        \n",
    "        # Dimensions\n",
    "        self.nA = len(self.a_grid)\n",
    "        self.nE = len(self.e_grid)\n",
    "        self.nTFP = len(self.tfp_grid)\n",
    "\n",
    "    def get_prices(self, K, Z):\n",
    "        # Cobb-Douglas Production\n",
    "        r = self.alpha * Z * K.pow(self.alpha - 1) - self.delta\n",
    "        w = (1 - self.alpha) * Z * K.pow(self.alpha)\n",
    "        return r, w\n",
    "\n",
    "    def utility_prime(self, c):\n",
    "        # CRRA Marginal Utility\n",
    "        return torch.pow(c + 1e-7, -self.gamma)\n",
    "\n",
    "    def utility_prime_inv(self, u_prime):\n",
    "        # Inverse Marginal Utility\n",
    "        return torch.pow(u_prime + 1e-7, -1.0 / self.gamma)\n",
    "\n",
    "    def fisher_burmeister(self, a, b):\n",
    "        # NCP function for Kuhn-Tucker conditions\n",
    "        # f(a,b) = a + b - sqrt(a^2 + b^2)\n",
    "        return a + b - torch.sqrt(a**2 + b**2 + 1e-7)\n",
    "\n",
    "    def compute_savings(self, network, agg_state, individual_state_indices):\n",
    "        ''' \n",
    "        Computes optimal savings given the Neural Network Policy.\n",
    "        agg_state: [TFP, Distribution Moments/Full Dist]\n",
    "        individual_state_indices: Tuple (idx_a, idx_e)\n",
    "        '''\n",
    "        # 1. Unpack State\n",
    "        idx_a, idx_e = individual_state_indices\n",
    "        a_val = self.a_grid[idx_a] # (Batch)\n",
    "        e_val = self.e_grid[idx_e] # (Batch)\n",
    "        \n",
    "        # 2. Prepare NN Input\n",
    "        # Normalize inputs slightly to help training\n",
    "        norm_a = (a_val - self.amin) / (self.amax - self.amin)\n",
    "        # Input Vector: [a, e, Aggregate_State...]\n",
    "        # Agg state is usually [Z, K]\n",
    "        nn_input = torch.cat([\n",
    "            norm_a.unsqueeze(-1), \n",
    "            e_val.unsqueeze(-1), \n",
    "            agg_state\n",
    "        ], dim=1)\n",
    "        \n",
    "        # 3. Get Savings Rate from NN\n",
    "        raw_output = network(nn_input)\n",
    "        savings_rate = torch.sigmoid(raw_output).squeeze()\n",
    "\n",
    "        # 4. Budget Constraint\n",
    "        # We need prices r and w. \n",
    "        # Assuming agg_state[:,0] is Z and agg_state[:,1] is K\n",
    "        Z = agg_state[:, 0]\n",
    "        K = agg_state[:, 1]\n",
    "        r, w = self.get_prices(K, Z)\n",
    "        \n",
    "        coh = (1 + r) * a_val + w * e_val\n",
    "        \n",
    "        # Policy\n",
    "        sav = self.amin + savings_rate * (coh - self.amin)\n",
    "        con = coh - sav\n",
    "        \n",
    "        return sav, con\n",
    "\n",
    "    def transport_distribution(self, sav_policy, dist_mass):\n",
    "        '''\n",
    "        Moves the histogram forward.\n",
    "        sav_policy: (Batch, nA, nE) - Savings choices for every grid point\n",
    "        dist_mass: (Batch, nA, nE) - Current mass at every grid point\n",
    "        '''\n",
    "        BatchSize = sav_policy.shape[0]\n",
    "        \n",
    "        # Flatten asset/productivity dims for processing\n",
    "        sav_flat = sav_policy.reshape(BatchSize, -1)\n",
    "        mass_flat = dist_mass.reshape(BatchSize, -1)\n",
    "        \n",
    "        # 1. Find indices on Asset Grid (Linear Interpolation logic)\n",
    "        # searchsorted expects 1D grid, we apply to each batch element\n",
    "        # Since grid is constant, we can use bucketize logic\n",
    "        idx_upper = torch.searchsorted(self.a_grid, sav_flat)\n",
    "        idx_upper = torch.clamp(idx_upper, 1, self.nA - 1)\n",
    "        idx_lower = idx_upper - 1\n",
    "        \n",
    "        a_lower = self.a_grid[idx_lower]\n",
    "        a_upper = self.a_grid[idx_upper]\n",
    "        \n",
    "        # Weights for interpolation\n",
    "        weight_upper = (sav_flat - a_lower) / (a_upper - a_lower + 1e-8)\n",
    "        weight_lower = 1.0 - weight_upper\n",
    "        \n",
    "        # 2. Prepare for Markov Transition (e -> e')\n",
    "        # The input `dist_mass` is at (a, e). We move it to a'. \n",
    "        # Then we must split it among e' based on Pi_e.\n",
    "        \n",
    "        # Initialize next period distribution\n",
    "        dist_next = torch.zeros(BatchSize, self.nA * self.nE, device=self.device)\n",
    "        \n",
    "        # Current indices (a, e) flattened: e changes every 1 step, a every nE steps?\n",
    "        # No, usually setup is [nA, nE]. a changes slowly, e fast? Or vice versa.\n",
    "        # Let's assume sav_policy is [Batch, nA, nE]. \n",
    "        # We need to map the mass to specific indices in the output vector.\n",
    "        \n",
    "        # Construct base indices for the `e` dimension\n",
    "        # For a specific source `e`, we distribute to all `e_prime`\n",
    "        \n",
    "        for e_from in range(self.nE):\n",
    "            # Select mass coming from state e_from\n",
    "            # Shape: [Batch, nA]\n",
    "            mass_slice = dist_mass[:, :, e_from].reshape(BatchSize, -1)\n",
    "            idx_l_slice = idx_lower.view(BatchSize, self.nA, self.nE)[:, :, e_from]\n",
    "            idx_u_slice = idx_upper.view(BatchSize, self.nA, self.nE)[:, :, e_from]\n",
    "            w_l_slice = weight_lower.view(BatchSize, self.nA, self.nE)[:, :, e_from]\n",
    "            w_u_slice = weight_upper.view(BatchSize, self.nA, self.nE)[:, :, e_from]\n",
    "            \n",
    "            # Loop over destination e_to\n",
    "            for e_to in range(self.nE):\n",
    "                prob = self.Pi_e[e_from, e_to]\n",
    "                if prob == 0: continue\n",
    "                \n",
    "                # Destination global indices in the flattened array (nA * nE)\n",
    "                # Structure: [a0e0, a0e1... a1e0...]\n",
    "                # So index = a_idx * nE + e_to\n",
    "                dest_idx_l = idx_l_slice * self.nE + e_to\n",
    "                dest_idx_u = idx_u_slice * self.nE + e_to\n",
    "                \n",
    "                # Add Mass\n",
    "                dist_next.scatter_add_(1, dest_idx_l, mass_slice * w_l_slice * prob)\n",
    "                dist_next.scatter_add_(1, dest_idx_u, mass_slice * w_u_slice * prob)\n",
    "                \n",
    "        return dist_next.view(BatchSize, self.nA, self.nE)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: The Training Loop (Cloud Simulation)\n",
    "\n",
    "We simulate a \"cloud\" of $N$ parallel economies. \n",
    "1. **Simulate:** Given current states, calculate next states (Aggregate K and TFP).\n",
    "2. **Loss:** Calculate Euler equation errors for random agents inside these economies."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def train_model(model_physics, n_epochs=2000, batch_size=256, n_agents_sample=64):\n",
    "    \n",
    "    # Initialize Network\n",
    "    # Input features: a (1) + e (1) + Z (1) + K (1) = 4 features\n",
    "    # Note: Detailed DEQN often uses more moments of dist, but for KS, mean K is sufficient.\n",
    "    net = KS_Network(n_input=4, n_hidden=64).to(device)\n",
    "    optimizer = optim.Adam(net.parameters(), lr=1e-3)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=500, gamma=0.5)\n",
    "    \n",
    "    # Initialize Cloud of Economies\n",
    "    n_cloud = batch_size\n",
    "    \n",
    "    # Initial Distribution (Start at Steady State)\n",
    "    # Shape: [Cloud, nA, nE]\n",
    "    current_dist = torch.tensor(ss_dist, dtype=torch.float32, device=device).unsqueeze(0).expand(n_cloud, -1, -1).clone()\n",
    "    \n",
    "    # Initial TFP (Randomly sampled)\n",
    "    current_tfp_idx = torch.randint(0, model_physics.nTFP, (n_cloud,), device=device)\n",
    "    \n",
    "    loss_history = []\n",
    "    \n",
    "    print(\"Starting Training...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # --- 1. Construct Aggregate State ---\n",
    "        # Calc Aggregate Capital K\n",
    "        # Sum(Mass * Asset_Grid)\n",
    "        # Dist: [Batch, nA, nE], Grid: [nA]\n",
    "        # Sum over nE, then dot product with Grid\n",
    "        marg_dist_a = current_dist.sum(dim=2) # [Batch, nA]\n",
    "        K_agg = (marg_dist_a * model_physics.a_grid).sum(dim=1) # [Batch]\n",
    "        \n",
    "        Z_curr = model_physics.tfp_grid[current_tfp_idx]\n",
    "        \n",
    "        agg_state = torch.stack([Z_curr, K_agg], dim=1) # [Batch, 2]\n",
    "        \n",
    "        # --- 2. Compute Euler Error (Loss) ---\n",
    "        # We sample random agents (a, e) to check their Euler errors\n",
    "        \n",
    "        # Sample indices\n",
    "        idx_a = torch.randint(0, model_physics.nA, (n_cloud, n_agents_sample), device=device)\n",
    "        idx_e = torch.randint(0, model_physics.nE, (n_cloud, n_agents_sample), device=device)\n",
    "        \n",
    "        # Expand agg_state for these agents\n",
    "        # agg_state_exp: [Batch, Agents, 2]\n",
    "        agg_state_exp = agg_state.unsqueeze(1).expand(-1, n_agents_sample, -1)\n",
    "        \n",
    "        # Flatten for NN processing\n",
    "        flat_idx_a = idx_a.reshape(-1)\n",
    "        flat_idx_e = idx_e.reshape(-1)\n",
    "        flat_agg = agg_state_exp.reshape(-1, 2)\n",
    "        \n",
    "        # Get Current Policies (c, a')\n",
    "        sav, con = model_physics.compute_savings(net, flat_agg, (flat_idx_a, flat_idx_e))\n",
    "        \n",
    "        # Calculate Marginal Utility u'(c)\n",
    "        mu = model_physics.utility_prime(con)\n",
    "        \n",
    "        # --- 3. Expectations (t+1) ---\n",
    "        # We need to forecast K' and Z'\n",
    "        # For K': We need to simulate the ENTIRE distribution forward\n",
    "        # This is the expensive part. We do it inside `no_grad` usually for simulation,\n",
    "        # but for loss calculation involving K', we technically need gradients if we want to solve for price consistency perfectly.\n",
    "        # However, DEQN standard approach: Take K' as given by the simulation step (Fixed Point iteration style).\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Compute policy for ALL grid points to move distribution\n",
    "            # Create full grid inputs [Batch, nA, nE, 2]\n",
    "            full_agg = agg_state.view(n_cloud, 1, 1, 2).expand(-1, model_physics.nA, model_physics.nE, -1)\n",
    "            full_a_idx = torch.arange(model_physics.nA, device=device).view(1, -1, 1).expand(n_cloud, -1, model_physics.nE)\n",
    "            full_e_idx = torch.arange(model_physics.nE, device=device).view(1, 1, -1).expand(n_cloud, model_physics.nA, -1)\n",
    "            \n",
    "            flat_full_agg = full_agg.reshape(-1, 2)\n",
    "            flat_full_a = full_a_idx.reshape(-1)\n",
    "            flat_full_e = full_e_idx.reshape(-1)\n",
    "            \n",
    "            sav_grid_flat, _ = model_physics.compute_savings(net, flat_full_agg, (flat_full_a, flat_full_e))\n",
    "            sav_grid = sav_grid_flat.view(n_cloud, model_physics.nA, model_physics.nE)\n",
    "            \n",
    "            # Move Distribution\n",
    "            next_dist = model_physics.transport_distribution(sav_grid, current_dist)\n",
    "            \n",
    "            # Calculate K_prime\n",
    "            marg_dist_next = next_dist.sum(dim=2)\n",
    "            K_next = (marg_dist_next * model_physics.a_grid).sum(dim=1)\n",
    "            \n",
    "            # Transition TFP (Sample next Z)\n",
    "            # For Euler error expectation, we sum over all possible Z_prime probabilities.\n",
    "        \n",
    "        # Calculate RHS of Euler: beta * E [ (1+r') * u'(c') ]\n",
    "        rhs_expectation = torch.zeros_like(mu)\n",
    "        \n",
    "        # Loop over possible future TFP states (Integration over aggregate shock)\n",
    "        for z_next_idx in range(model_physics.nTFP):\n",
    "            prob_z = model_physics.Pi_tfp[current_tfp_idx, z_next_idx] # [Batch]\n",
    "            # Mask for efficiency\n",
    "            # (In simple code, we just compute all)\n",
    "            \n",
    "            Z_next = model_physics.tfp_grid[z_next_idx].repeat(n_cloud)\n",
    "            r_next, _ = model_physics.get_prices(K_next, Z_next)\n",
    "            \n",
    "            # Integration over Idiosyncratic Shock (e')\n",
    "            # The agent at (a, e) saved `sav`. In t+1, they have assets `sav`.\n",
    "            # Their `e` transitions to `e_prime`.\n",
    "            \n",
    "            # We need c_prime for the agent. \n",
    "            # State: Assets=sav (continuous), e=e_prime, Agg=(Z_next, K_next)\n",
    "            \n",
    "            # Expand for agents\n",
    "            r_next_exp = r_next.unsqueeze(1).expand(-1, n_agents_sample).reshape(-1)\n",
    "            Z_next_exp = Z_next.unsqueeze(1).expand(-1, n_agents_sample).reshape(-1)\n",
    "            K_next_exp = K_next.unsqueeze(1).expand(-1, n_agents_sample).reshape(-1)\n",
    "            \n",
    "            # Current savings become next period assets\n",
    "            a_prime = sav.detach() # [Batch * Agents]\n",
    "            # Note: Inputs to NN for 'a' need to be on grid? \n",
    "            # No, NN takes continuous values. But our wrapper `compute_savings` assumed indices.\n",
    "            # We need a raw access method for continuous 'a'.\n",
    "            \n",
    "            # -- Inline continuous evaluation for t+1 --\n",
    "            norm_a_prime = (a_prime - model_physics.amin) / (model_physics.amax - model_physics.amin)\n",
    "            agg_next_exp = torch.stack([Z_next_exp, K_next_exp], dim=1)\n",
    "            \n",
    "            # We must sum over e_prime\n",
    "            expected_val_given_z = 0\n",
    "            \n",
    "            for e_prime_idx in range(model_physics.nE):\n",
    "                # Prob of e -> e'q\n",
    "                prob_e = model_physics.Pi_e[flat_idx_e, e_prime_idx] # [Batch*Agents]\n",
    "                \n",
    "                e_prime_val = model_physics.e_grid[e_prime_idx].repeat(n_cloud * n_agents_sample)\n",
    "                \n",
    "                nn_input_next = torch.cat([\n",
    "                    norm_a_prime.unsqueeze(-1),\n",
    "                    e_prime_val.unsqueeze(-1),\n",
    "                    agg_next_exp\n",
    "                ], dim=1)\n",
    "                \n",
    "                # Get c_prime\n",
    "                out_next = net(nn_input_next)\n",
    "                sav_rate_next = torch.sigmoid(out_next).squeeze()\n",
    "                \n",
    "                # Budget t+1\n",
    "                # w_next depends on Z_next, K_next\n",
    "                _, w_next = model_physics.get_prices(K_next_exp, Z_next_exp)\n",
    "                \n",
    "                coh_next = (1 + r_next_exp) * a_prime + w_next * e_prime_val\n",
    "                c_prime = coh_next - (model_physics.amin + sav_rate_next * (coh_next - model_physics.amin))\n",
    "                \n",
    "                mu_prime = model_physics.utility_prime(c_prime)\n",
    "                \n",
    "                expected_val_given_z += prob_e * (1 + r_next_exp) * mu_prime\n",
    "            \n",
    "            # Add to total expectation (weighted by Z prob)\n",
    "            prob_z_exp = prob_z.unsqueeze(1).expand(-1, n_agents_sample).reshape(-1)\n",
    "            rhs_expectation += prob_z_exp * expected_val_given_z\n",
    "            \n",
    "        rhs = model_physics.beta * rhs_expectation\n",
    "        \n",
    "        # Fischer-Burmeister Error (accounts for borrowing constraint)\n",
    "        # f(Euler, Constraint)\n",
    "        # Euler Residual: 1 - RHS/LHS\n",
    "        # Or simpler: u'(c) - beta * E...\n",
    "        \n",
    "        diff = 1.0 - rhs / mu\n",
    "        loss = torch.mean(diff**2)\n",
    "        \n",
    "        # --- 4. Optimization ---\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        loss_history.append(loss.item())\n",
    "        \n",
    "        # --- 5. Simulation Step (Update Cloud State) ---\n",
    "        # We effectively did this in step 3 to get K_next. \n",
    "        # Now we just update the pointers for the next loop.\n",
    "        current_dist = next_dist.detach()\n",
    "        \n",
    "        # Sample actual next Z for the cloud\n",
    "        # Use vectorized multinomial sampling\n",
    "        probs = model_physics.Pi_tfp[current_tfp_idx] # [Batch, nTFP]\n",
    "        current_tfp_idx = torch.multinomial(probs, 1).squeeze()\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch} | Loss: {loss.item():.6f} | K_agg: {K_agg.mean().item():.3f}\")\n",
    "\n",
    "    print(f\"Training Complete. Final Loss: {loss.item():.6f}\")\n",
    "    return net, loss_history, current_dist\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Setup Physics\n",
    "ks_ss_data = {'a_grid': ss_a_grid, 'e_grid': ss_e_grid, 'Pi_e': ss_Pi_e}\n",
    "tfp_data = {'grid': tfp_grid, 'Pi': Pi_tfp}\n",
    "\n",
    "model = KrusellSmithModel(calibration, ks_ss_data, tfp_data, device)\n",
    "\n",
    "# Run Training\n",
    "trained_net, history, final_dist = train_model(model, n_epochs=2000)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Analysis and Plotting"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(np.log10(history))\n",
    "plt.title(\"Training Loss (Log10)\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Log Loss\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Check the Policy Function\n",
    "def plot_policy(net, model, k_level_idx=2, z_level_idx=2):\n",
    "    # Setup inputs\n",
    "    a_vals = model.a_grid\n",
    "    e_vals = model.e_grid\n",
    "    \n",
    "    # Fix Aggregate State\n",
    "    Z = model.tfp_grid[z_level_idx]\n",
    "    K = torch.tensor([ss_K], device=device) # Use steady state K\n",
    "    \n",
    "    agg_vec = torch.stack([Z, K]).view(1, 2).expand(len(a_vals), 2)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, e in enumerate(e_vals):\n",
    "            # Create inputs\n",
    "            norm_a = (a_vals - model.amin) / (model.amax - model.amin)\n",
    "            nn_in = torch.cat([norm_a.unsqueeze(1), \n",
    "                               e.repeat(len(a_vals)).unsqueeze(1),\n",
    "                               agg_vec], dim=1)\n",
    "            \n",
    "            sav_rate = torch.sigmoid(net(nn_in)).squeeze()\n",
    "            \n",
    "            # Budget\n",
    "            r, w = model.get_prices(K, Z)\n",
    "            coh = (1+r)*a_vals + w*e\n",
    "            sav = model.amin + sav_rate * (coh - model.amin)\n",
    "            \n",
    "            plt.plot(a_vals.cpu(), sav.cpu(), label=f\"Productivity e={e:.2f}\")\n",
    "            \n",
    "    plt.plot(a_vals.cpu(), a_vals.cpu(), 'k--', alpha=0.5, label=\"45 degree\")\n",
    "    plt.xlabel(\"Assets (a)\")\n",
    "    plt.ylabel(\"Savings (a')\")\n",
    "    plt.title(f\"Savings Policy Function (at K={ss_K:.2f}, Z={Z:.2f})\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "plot_policy(trained_net, model)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
